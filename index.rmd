---
title: "Мой отчет"
author: "Я"
date: '26 марта 2017 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Пакет dplyr

Моделирование в той или иной форме является составной частью более сложного процесса, через который проходит любой исследователь работающий с реальными данными -  анализ данных. Не вдаваясь глубоко в подробности в данном разделе будет рассмотрен начальный этап анализа данных - преобразования или манипуляции с данными (data-manipulation).

В целом мы уже рассматривали некоторые функции языка R, которые можно использовать для манипцляции данными, меж тем помимо классической парадигмы существует ряд широко распространненных пакетов, которые позволяют проводить ряд операций в более явном виде и используя меньше кода. Давайте рассмотрим ряд из самых популярных подобных пакетов  из целой "вселенной" пакетов tydiverse от известного разработчика Хадли Викхема.

```{r}
library("tidyverse")
library("nycflights13")
library("tidyr")
library("stringr")
library("dplyr")
library("tibble")
library("readr")

```
Изучение пакета dplyr мы начнем со следующих функций:

  * filter()
  * arrange()
  * select()
  * mutate()
  * summarize()
  * group_by()
  
  
Filter () позволяет выбрать подмножество наблюдений(строк), основанных на их значениях(по значениям в отдельных колонках). Первый аргумент функции - это имя таблицы данных. Второй и последующие аргументы - это выражения, которые фильтруют фрейм данных, которые должны в результате выдавать логический вектор. Рассмотрим данные по времени и датам вылетов из набора данных flights, которые мы подключили с пакетом nycflights13, и выберем все рейсы с 1 января:

```{r}

filter(flights, month == 1, day == 1)
```

Следующий код находит все рейсы, отправленные в ноябре или декабре:

```{r}
filter(flights, month == 11 | month == 12)
```

Полезным конструкцией для решения подобных  проблем является x %in% y. Она выберет каждую строку, где x является одним из значений y. Мы могли бы использовать его для перезаписи предыдущего кода:

```{r}
nov_dec <- filter(flights, month %in% c(11, 12))
```

arrange()  работает аналогично filter(), за исключением того, что вместо выбора строк изменяется их порядок. Он принимает таблицу данных и набор имен столбцов (или более сложных выражений) для упорядочения. Если вы укажете более одного имени столбца, каждый дополнительный столбец будет использоваться для разрыва связей в значениях предыдущих столбцов:

```{r}
arrange(flights, year, month, day)
arrange(flights, desc(arr_delay))
```

Функция desc() говорит о том, что колонку нужно пересортировать от большего к меньшему

Это не редкость, когда приходиться работать с наборами данных с сотнями или даже тысячами переменных. В этом случае первая задача часто сводится к получению таблицы с набором переменных, которые вам действительно интересны. Select() позволяет быстро получить полезное подмножество, используя операции, основанные на именах переменных.

```{r}
select(flights, year, month, day)
```

Интересной особенностью является возможностью выбирать ряд колонок меж двух заданных

```{r}
select(flights, year:day)
select(flights, -(year:day))
```

Помимо выбора наборов существующих столбцов, часто полезно добавлять новые столбцы, которые являются функциями существующих столбцов. Это задача функции mutate().

```{r}
flights_sml <- select(flights, year:day, ends_with("delay"), distance, air_time )
mutate(flights_sml, gain = arr_delay - dep_delay, speed = distance / air_time * 60)
```

Последний ключевой глагол - summarize((). Он сворачивает фрейм данных в одну строку:

```{r}
summarize(flights, delay = mean(dep_delay, na.rm = TRUE))
```

Функция summarize() не очень полезна, если мы будем сипользовать ее без group_by (). Она изменяет единицу анализа от полного набора данных к отдельным группам. Затем, когда вы используете функции dplyr в сгруппированном фрейме данных, они будут автоматически применяться «по группам». Например, если мы применили точно такой же код к таблице данных, сгруппированным по дате, мы получим среднюю задержку на дату:

```{r}
by_day <- group_by(flights, year, month, day)
summarize(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

Вместе функции group_by() и summarize() предоставляют один из инструментов, который вы будете использовать наиболее часто при работе с dplyr: сгруппированные заключения по данными в виде вектора. Но прежде чем мы пойдем дальше, нам нужно ввести новую мощную идею: пайпинг(сборка команды в последовательности - трубы).

Представьте, что мы хотим изучить связь между расстоянием и средней задержкой для каждого местоположения. Используя то, что вы знаете о dplyr, вы можете написать код следующим образом:

Оператор папинга %>% очень удобен для объединения нескольких функций dplyr в последовательность операций. Обратите внимание, что каждый раз, когда мы хотели применить более одной функции, последовательность вкладывается в последовательности вложенных вызовов функций, которые очень трудно читать, например:

```{}
third(second(first(x)))
```

Это сильно отличается от того, как мы думаем и представляем себе последовательность операций. Оператор %>% позволяет вам выполнять последовательность операции  слева направо, т. е.

```{}
First (x) %>% second %>% third
```

Например, последние наши действия можно теперь записать более наглядным образом:

```{r}
group_by(flights, year, month, day) %>% summarize( delay = mean(dep_delay, na.rm = TRUE))
```

##Разбор возможностей пакетов на примере реальных данных

Возьмем данные из второй задачи по регресиионному линейному анализу и попытаемся подготовить их корелляционному анализу. Воспользуемся функцией read_csv из пакета readr. Она во многои сходна с хорошо известной вам read.csv, но обладает рядом полезных параметров, которые мы попытаемся для себя использовать

```{r}
tbl = read_csv("https://www.dropbox.com/s/erhs9hoj4vhrz0b/eddypro.csv?dl=1")
tbl
```

Первое на что вы должны обратить внимание, это то, что полученный в результате объект не является привычным нам data.frame, а некой новой структурой типа 
tibble. Точнее, на самом деле он является и data.frame тоже и в этом легко убедиться:

```{r}
class(tbl)
```

Дело в том, что пакет readr использует пакет tibble из набора tidyverse и преобразует все таблицы в tibble. С tibble вы можете пользоваться 99% всех функций, которыми вы пользовались с data.frame, но помимо этого, он обладает огромным количеством улучшений и "украшательств". Первое из них, это то, как выглядит вывод таблицы. Теперь вы видите только ту ее часть, что помещается на вашем экране, а все остальная информация дается сжато.

Если вернуться к нашей таблице, то мы увидим ряд проблем связанных с ее неправильной организацией. Во первых, первая строчка не содержит имена переменных, а содержит некоторые к ним комментарии, в то время как имена переменных находятся во второй строчке. Соответственно мы должны при чтении файла пропустить первую строчку и начать считывать файл только со второй. Именно для этого большинство функций чтения имеют параметр skip:

```{r}
tbl = read_csv("https://www.dropbox.com/s/erhs9hoj4vhrz0b/eddypro.csv?dl=1", skip =1)
tbl
```

Как мы видим, теперь проблема решена. Обратите внимание, что readr при чтении таблицы выдает большое количество предупреждений, но при этом продолжает работать. Основная идея авторов заключалась в том, чтобы с одной стороны сделать функцию работающей с самыми сложными и неадекватными данными, но при этом с высокими требованиями к качеству организации данных. Что является взаимноисключающими требованиями, поэтому функции пакета работают с практически любыми данными, но выдают большое количество предупреждений и рекомендаций по их качеству, плюс, например в нашем случае, совершают ряд действий для решения проблем - например переименовывают переменные.

Продолжим изучение нашей таблицы данных. Благодаря подробной выдаче tibble легко заметить, что  все переменные в таблице имеют тип char, что не соответствует действительности. Причиной этого явлется первая строчка таблицы, которая вместо данных содержит их размерность. В принципе удаление строчки не представляет проблемы и мы могли бы избавится от нее стандартным образом tbl = tbl[-1,]. Но это не отменит того факта, что все колонки у нас в талице теперь типа char. Функции пакета readr позволяют нам решить многие проблемы еще на фазе чтения. Воспользуемся параметром comment, который заставляет readr игнорировать все строчки, содержащие определенный символ, легко заметить, что в нашем случае это будет символ "["

```{r}
tbl = read_csv("https://www.dropbox.com/s/erhs9hoj4vhrz0b/eddypro.csv?dl=1", skip = 1, comment=c("["))
tbl
```

Проблема с типами колонок теперь решена, но мешавшая нам строчка осталась, содержит она только NA и теперь мы точно можем от нее избавиться. Говоря об NA давайте вспомним, что полученные нами данные являются машинно сгенерированными и для обозначения отсутствия данных генератором использовалось значение -9999. Это значение несет в себе информацию аналогичную значению NA в R, а значит мы должны найти и заменить все такие значения. Это действие тоже можно проделать еще на стадии считывания файла

```{r}
tbl = read_csv("https://www.dropbox.com/s/erhs9hoj4vhrz0b/eddypro.csv?dl=1", skip = 1, na =c("","NA","-9999","-9999.0"), comment=c("["))
tbl = tbl[-1,]
tbl
```

Теперь данные имеют адекватный вид и мы сделали все, что можно еще на стадии их прочтения. Давайте внимательнее посмотрим на сами переменные и для этого воспользуеся функцией glimpse(), которая более наглядно представляет каждую отдельную переменную, жертуя при этом предсталение строчек данных

```{r}
glimpse(tbl)
```

При внимательном рассмотрении можно заметить, что переменная roll содержит только NA, а потому будет только мешать нам при анализе. Избавимся от нее с помощью функции select:

```{r}
tbl = select(tbl, -(roll))
```

В нашей таблице довольно много переменных типа char, которые содержат повторяющиеся значения, т.к. их текст, как таковой нас не интересует, преобразуем их все в факторы:

```{r}
tbl = tbl %>% mutate_if(is.character, factor)
```

Здесь мы использовали функию mutate_if которая делает преобразование над колонкой - factor() при полученни значения TRUE от функции первого параметра - is.character().

Следующее действие не совершенно не обязательно, но в определенных условиях может сильно упростить вам жизнь. Дело в том, что многие функции, которые работаю с множествами переменных могу рассматривать знаки в именах переменных, как действия над ними, что будет приводить к ошибкам. Так, например, у нас в таблице есть переменные "(z-d)/L", " u*","x_90% " и т.д. Формально этого лучше избегать и использовать только буквы, цифры, нижнее подчеркивание и точки. Т.к. большинство данных, с которыми вам придется работать не будут соответствовать этим критериям, то попытаемся научиться решать эту проблему используя наши данные.

Для этого мы используем функцию str_replace_all из пакета stringr. Она позволяет, использую довольно простой синтаксис, заменить ненужные нам символы:

```{r}
names(tbl) =  str_replace_all(names(tbl), "[!]","_emph_")
```

В данном примере, мы говорим, что теперь все имена таблицы должны быть некоторым вектором строк от функции str_replace_all, которая в свою очередь берет все имена из таблицы tbl, заменяет в них все ! на "_emph_" и возвращает их  в виде вектора. Все довольно наглядно, но проблема в том, что нам нужно сделать такое последовательно много раз(т.к. нам нужно избавиться не только от !), что приведет к совершенно не читаемому результату. Поэтому воспользуеися оператором пайппинга

```{r}
names(tbl) = names(tbl) %>% 
  str_replace_all("[!]","_emph_") %>% 
  str_replace_all("[?]","_quest_") %>% 
  str_replace_all("[*]","_star_") %>% 
  str_replace_all("[+]","_plus_") %>%
  str_replace_all("[-]","_minus_") %>%
  str_replace_all("[@]","_at_") %>%
  str_replace_all("[$]","_dollar_") %>%
  str_replace_all("[#]","_hash_") %>%
  str_replace_all("[/]","_div_") %>%
  str_replace_all("[%]","_perc_") %>%
  str_replace_all("[&]","_amp_") %>%
  str_replace_all("[\\^]","_power_") %>%
  str_replace_all("[()]","_") 
glimpse(tbl)
```

Функция cor работает только с численными данными, поэтому, чтобы перейти к корелляционному анализу нужно выбрать все переменные типа numeric. Для этого воспользуемся двумя функциями - is.numeric(), которая выдает TRUE в случае если вектор является численныи и sapply(), которая берет каждую колонку таблицы, передает ее в функию в виде вектора(в нашем случае этой функцией будет is.numeric) и выдает результат в виде вектора длинной равной количеству колонок в таблице. Давайте проверим, что получится

```{r}
sapply(tbl,is.numeric)
```

Для каждой колонки таблицы мы получили значение правда, если она является численной и ложь, если не является. Осталось подставить этот вектор в саму таблицу и получить таблицу состояющую только из интересующих нас колонок

```{r}
tbl_numeric = tbl[,sapply(tbl,is.numeric) ]
```

При этом очень легко получить таблицу содержащую все остальные колонки

```{r}
tbl_non_numeric = tbl[,!sapply(tbl,is.numeric) ]
```

Теперь мы можем переходить к корелляционному анализу (если вы не помните, что это мы подробно рассмотрим его в следующей части):

```{r}
cor_td = cor(tbl_numeric)
cor_td
```

Ничего не вышло, проблема в том, что почти каждая из переменных содержит пропуски, а это приводит к тому, что невозможно провести попарную ковариацию, что ячляется первой частью корелляционного анализа. Это означает, что нам необходимо избаиться от все строк где есть хоть одно значение NA. Воспользуемся для этого готовой функцией drop_na()

```{r}
cor_td = cor(drop_na(tbl_numeric))
cor_td
```

Полученные результаты довольно тяжело интерпретировать т.к. они выдаются в виде матрицы, поэтому преобразуем матрицу в таблицу, выберем интересующий нас столбец, а из него возьмем только те имена строк(переменных) для которых значения коэффициента детерминации было больше 0,1 (личная прихоть) 

```{r}
cor_td = cor(drop_na(tbl_numeric)) %>% as.data.frame %>% select(co2_flux)
vars = row.names(cor_td)[cor_td$co2_flux^2 > .1] %>% na.exclude
```

Несколько советов для регрессионного анализа. Собрать все переменные из вектора с именнами переменных в одну формулу можно следующим образом:
```{r}
formula = as.formula(paste("co2_flux~", paste(vars,collapse = "+"), sep=""))
formula
```

Создать произвольные(возможно пересекающиеся) обучающую и тестирующую выборки можно с помощью команды sample_n из пакета dplyr

```{r}
teaching_tbl = sample_n(tbl, floor(length(tbl$date)*.7))
testing_tbl = sample_n(tbl, floor(length(tbl$date)*.3))
```

Если вы хотите сделать непересекающиеся подвыборки, то это можно сделать базовым набором функций

```{r}
row_numbers = 1:length(tbl$date)
teach = sample(row_numbers, floor(length(tbl$date)*.7))
test = row_numbers[-teach]

teaching_tbl_unq = tbl[teach,]
testing_tbl_unq = tbl[test,]
```



